---
permalink: /
title: "About me"
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I am a PhD student in Computer Science at UIUC, advised by Prof. [Tong Zhang](http://tongzhang-ml.org) and Prof. [Huan Zhang](https://www.huan-zhang.com). Previously, I earned my bachelor's and master's degrees from the Department of Automation at Tsinghua University and CSE, HKUST. My current research interests lie in **Foundation Models for Agents**, **Trustworthy LLMs/VLMs**, and **Deep Reinforcement Learning**. My long-term goal is to develop **agent foundation models with strong perception, reasoning, and planning capabilities**, enabling scalable and reliable autonomous systems.


Prior to my PhD, I was fortunate to work closely with Prof. [Chongjie Zhang](https://engineering.wustl.edu/faculty/Chongjie-Zhang.html) (Washington University in St. Louis), Dr. [Lei Han](http://www.leihan.org) (Noitom Robotics, formerly Tencent AI Lab), and Prof. [Meng Fang](https://mengfn.github.io) (University of Liverpool). 



## News {#news}
- **ðŸŽ‰ (2026.1)** [BEAT](https://arxiv.org/abs/2510.27623) and [DROCO](https://arxiv.org/abs/2512.02486) are accepted to **ICLR 2026**. Congrats to all co-authors!
- **ðŸŽ‰ (2025.11)** [MiCRo](https://arxiv.org/abs/2505.24846) won the <span style="color:DodgerBlue;">**EMNLP 2025 Outstanding Paper Award**</span>. Huge congrats to the team!
- **ðŸŒŸ (2025.11)** Check out our new paper about visual backdoor attacks on VLM-based embodied agents [BEAT](https://arxiv.org/abs/2510.27623)!
- **ðŸŒŸ (2025.10)** We released [Embodied Reasoning Agent (ERA)](https://arxiv.org/abs/2510.12693), a training recipe for VLM-based embodied agents with enhanced reasoning and grounding capability. Explore more on our [project page](https://embodied-reasoning-agent.github.io/).
- **ðŸŽ‰ (2025.9)** [GUI-Actor](https://arxiv.org/abs/2506.03143) and [ADG](https://arxiv.org/abs/2505.23871) are accepted to **NeurIPS 2025**! [MergeBench](https://arxiv.org/abs/2505.10833) is accepted to the **Datasets & Benchmarks Track**! Congrats to all co-authors!
- **ðŸŽ‰ (2025.8)** [MiCRo](https://arxiv.org/abs/2505.24846) is accepted to **EMNLP 2025** main conference with <span style="color:DodgerBlue;">**award nomination**</span>!
- **ðŸŒŸ (2025.6)** Weâ€™ve released [GUI-Actor](https://arxiv.org/abs/2506.03143), a novel GUI grounding model that combines an attention-based action head with a grounding verifier. Explore more on our [project page](https://microsoft.github.io/GUI-Actor/)!
- **ðŸ’» (2025.5)** Starting my internship at Microsoft Research, Redmond.
- **ðŸŽ‰ (2025.5)** [Decomposed Reward Models (DRMs)](https://arxiv.org/pdf/2502.13131) is accepted to **ACL 2025**.
- **ðŸŽ‰ (2025.5)** [EmbodiedBench](https://github.com/EmbodiedBench/EmbodiedBench) is accepted to **ICML 2025** as an <span style="color:DodgerBlue;">**oral**</span> paper! Thanks to my co-authors!
- **ðŸŒŸ (2025.02)** We released [EmbodiedBench](https://github.com/EmbodiedBench/EmbodiedBench), a new comprehensive and multifaceted benchmark for multimodal embodied agents. Check out our [paper](https://arxiv.org/abs/2502.09560) and [project page](https://embodiedbench.github.io/).
- **ðŸŽ‰ (2025.1)** [Robust Decision Transformer](https://arxiv.org/abs/2407.04285) and [DynaMath](https://arxiv.org/abs/2411.00836) are accepted by **ICLR 2025**! New versions will be updated soon.
- **ðŸŒŸ (2024.10)** A dynamic visual math benchmark is out! Check the [project page](https://dynamath.github.io) and the [DynaMath paper](https://huan-zhang.com/DynaMath.pdf).
- **ðŸŽ‰ (2024.9)** [GRM](https://arxiv.org/abs/2406.10216) is accepted by **NeurIPS 2024**! Check out our GRM series [here](https://github.com/YangRui2015/Generalizable-Reward-Model).
- **ðŸŽ‰ (2024.5)** [Rewards-in-Context (RiC)](https://arxiv.org/abs/2402.10207) is accepted by **ICML 2024**! Thanks to my co-authors!
- **ðŸŽ‰ (2024.1)** [Robust IQL](https://openreview.net/forum?id=5hAMmCU0bK) is accepted by **ICLR 2024** as a <span style="color:DodgerBlue;">**spotlight**</span> paper!

---
## Selected Projects (Led or Co-Led) {#publications}

### Multimodal GUI Agent and Embodied Agent

- **[ERA: Transforming VLMs into Embodied Agents via Embodied Prior Learning and Online Reinforcement Learning](https://arxiv.org/abs/2510.12693)**. *Preprint 2025* [\[code\]](https://github.com/Embodied-Reasoning-Agent/Embodied-Reasoning-Agent) [\[website\]](https://embodied-reasoning-agent.github.io/)    
  Hanyang Chen\$^\*$,  Mark Zhao\$^\*$,  **Rui Yang**$^\*$,  Qinwei Ma,  Ke Yang, Kangrui Wang,  Hao Bai,  Zhenhailong Wang,  Jiarui Yao,  Rui Pan,  Mengchao Zhang,  Jose Barreiros,  Aykut Onol, ChengXiang Zhai,  Heng Ji,  Manling Li,  Huan Zhang,  Tong Zhang.


- **[EmbodiedBench: Comprehensive Benchmarking Multi-modal Large Language Models for Vision-Driven Embodied Agents](https://arxiv.org/abs/2502.09560)**. **ICML 2025** <span style="color:red;">**(Oral)**</span>. [[code]](https://github.com/EmbodiedBench/EmbodiedBench) [[website]](https://embodiedbench.github.io/)  
  **Rui Yang**$^\*$, Hanyang Chen\$^\*$, Junyu Zhang\$^\*$, Mark Zhao$^\*$, Cheng Qian, Kangrui Wang, Qineng Wang, Teja Venkat Koripella, Marziyeh Movahedi, Manling Li, Heng Ji, Huan Zhang, Tong Zhang.

- **[GUI-Actor: Attention-based Grounding with Verifiable Action Head for GUI Agents](https://arxiv.org/abs/2506.03143)**. **NeurIPS 2025**. [\[code\]](https://github.com/microsoft/GUI-Actor) [\[website\]](https://microsoft.github.io/GUI-Actor)    
  Qianhui Wu\$^\*\$, Kanzhi Cheng\$^\*\$, **Rui Yang**\$^\*\$, Chaoyun Zhang, Jianwei Yang, Huiqiang Jiang, Jian Mu, Baolin Peng, Bo Qiao, Reuben Tan, Si Qin, Lars Liden, Qingwei Lin, Huan Zhang, Tong Zhang, Jianbing Zhang, Dongmei Zhang, Jianfeng Gao.

### Multimodal Math Reasoning 
- **[DynaMath: A Dynamic Visual Benchmark for Evaluating Mathematical Reasoning Robustness of Vision Language Models](https://arxiv.org/abs/2411.00836)**. **ICLR 2025**. [[code]](https://github.com/DynaMath/DynaMath) [[website]](https://dynamath.github.io/)  
  Chengke Zou $^\*$, Xingang Guo $^\*$, **Rui Yang** $^\*$, Junyu Zhang, Bin Hu, Huan Zhang.

### ML for LLMs
- **[Regularizing Hidden States Enables Learning Generalizable Reward Model for LLMs](https://arxiv.org/abs/2406.10216)**. **NeurIPS 2024**. [[code]](https://github.com/YangRui2015/Generalizable-Reward-Model)  
  **Rui Yang**, Ruomeng Ding, Yong Lin, Huan Zhang, Tong Zhang.

- **[Rewards-in-Context: Multi-objective Alignment of Foundation Models with Dynamic Preference Adjustment](https://arxiv.org/abs/2402.10207)**. **ICML 2024**. [[code]](https://github.com/YangRui2015/RiC)  
  **Rui Yang** $^\*$, Xiaoman Pan $^\*$, Feng Luo $^\*$, Shuang Qiu $^\*$, Han Zhong, Dong Yu, Jianshu Chen.

- **[Rethinking Diverse Human Preference Learning through Principal Component Analysis](https://arxiv.org/abs/2502.13131)**. **ACL 2025 (Findings)**.  
  Feng Luo$^\*$, **Rui Yang$^\*$**, Hao Sun, Chunyuan Deng, Jiarui Yao, Jingyan Shen, Huan Zhang, Hanjie Chen.  

- **[MiCRo: Mixture Modeling and Context-aware Routing for Personalized Preference Learning](https://arxiv.org/abs/2505.24846)**. **EMNLP 2025 (Main)** <span style="color:red;">**Outstanding Paper Award**</span>.  
  Jingyan Shen$^\*$, Jiarui Yao$^\*$, **Rui Yang$^\*$**, Yifan Sun, Feng Luo, Rui Pan, Tong Zhang, Han Zhao.  

  

### Robust Offline RL

- **[Robust Decision Transformer: Tackling Data Corruption in Offline RL via Sequence Modeling](https://openreview.net/forum?id=phAlw3JPms)**. **ICLR 2025**.  
  Jiawei Xu $^\*$, **Rui Yang** $^\*$, Shuang Qiu, Feng Luo, Meng Fang, Baoxiang Wang, Lei Han.

- **[Towards Robust Offline Reinforcement Learning under Diverse Data Corruption](https://openreview.net/forum?id=5hAMmCU0bK)**. **ICLR 2024**. <span style="color:red;">**(Spotlight)**</span> [[code]](https://github.com/YangRui2015/RIQL)  
  **Rui Yang** $^\*$, Han Zhong $^\*$, Jiawei Xu $^\*$, Amy Zhang, Chongjie Zhang, Lei Han, Tong Zhang.

- **[Corruption-Robust Offline Reinforcement Learning with General Function Approximation](https://openreview.net/forum?id=K9M7XNS9BX)**. **NeurIPS 2023**. [[code]](https://github.com/YangRui2015/UWMSG)  
  Chenlu Ye $^\*$, **Rui Yang** $^\*$, Quanquan Gu, Tong Zhang.

- **[RORL: Robust Offline Reinforcement Learning via Conservative Smoothing](https://openreview.net/forum?id=_QzJJGH_KE)**. **NeurIPS 2022**. <span style="color:red;">**(Spotlight)**</span> [[code]](https://github.com/YangRui2015/RORL)  
  **Rui Yang** $^\*$, Chenjia Bai $^\*$, Xiaoteng Ma, Zhaoran Wang, Chongjie Zhang, Lei Han.

### Goal-conditioned RL
- **[What Is Essential for Unseen Goal Generalization of Offline Goal-conditioned RL?](https://openreview.net/forum?id=UrQySwOk4q)**. **ICML 2023**. [[code]](https://github.com/YangRui2015/GOAT)  
  **Rui Yang**, Yong Lin, Xiaoteng Ma, Hao Hu, Chongjie Zhang, Tong Zhang.

- **[Rethinking Goal-conditioned Supervised Learning and Its Connection to Offline RL](https://openreview.net/forum?id=KJztlfGPdwW)**. **ICLR 2022**. [[code]](https://github.com/YangRui2015/AWGCSL)  
  **Rui Yang**, Yiming Lu, Wenzhe Li, Hao Sun, Meng Fang, Yali Du, Xiu Li, Lei Han, Chongjie Zhang.


---


## Experiences {#experiences}
- Research Intern at Microsoft Research, 2025.

- Research Intern at Tencent AI Lab and Robotics X Lab, 2020-2022 (Multiple internship terms).

- Machine Learning Intern at Meituan, 2019.




## Services {#services}

Conference Reviewer: ICML, ICLR, NeurIPS (<span style="color:red;">Top Reviewer</span> in NeurIPS 2023), ACL/ARR, ICRA, AAMAS.

Journal Reviewer: IEEE Robotics and Automation Letters (RA-L), IEEE Transactions on Neural Networks and
Learning Systems (TNNLS), IEEE Transactions on Artificial Intelligence (TAI), Machine Learning, Journal of Artificial Intelligence Research.

Teaching Assistant: COMP 4211 Machine Learning, HKUST; COMP 1021 Introduction to Computer Science, HKUST


## Hobbies {#others}

In my leisure time, I enjoy sports like running, table tennis, and swimming. During my time at Tsinghua University, I was an amateur long-distance runner. In 2019, I completed a half marathon (21.0975 km) in 1 h 30 min and a full marathon (42.195 km) in 3 h 36 min. However, since starting my PhD I havenâ€™t had time for regular running training, so Iâ€™ve let it slide. Hopefully Iâ€™ll get a chance to update my record once I graduateðŸ™‚.
