---
permalink: /
title: "About me"
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I am a CS PhD student at UIUC, advised by Prof. [Tong Zhang](http://tongzhang-ml.org) and Prof. [Huan Zhang](https://www.huan-zhang.com). Previously, I earned my bachelor's and master's degrees from the Department of Automation at Tsinghua University and CSE, HKUST. My research interests lie in deep reinforcement learning (RL) and the application of RL algorithms to Large Language Models (LLMs). I am furtunate to have been working closely with Prof. [Chongjie Zhang](https://engineering.wustl.edu/faculty/Chongjie-Zhang.html) (Washington University in St. Louis), Dr. [Lei Han](http://www.leihan.org) (Tencent AI Lab), and Prof. [Meng Fang](https://mengf1.github.io) (University of Liverpool). 

Currently, I am actively researching ways to improve the robustness and generalization abilities of deep reinforcement learning, while also trying to enhance the trustworthiness of LLMs. Feel free to contact me by email if you are interested in discussing or collaborating with me. 

News
------
- ðŸŽ‰ (2024.5) [Rewards-in-Context (RiC)](https://arxiv.org/abs/2402.10207) is accepted by ICML 2024! Thanks to my co-authors!
- ðŸŽ‰ (2024.5) [GOPlan](https://openreview.net/forum?id=zOKAmm8R9B) is accepted by Transactions on Machine Learning Research (TMLR)!
- ðŸŽ‰ (2024.1) [Robust IQL](https://openreview.net/forum?id=5hAMmCU0bK) is accepted by ICLR 2024 as a spotlight paper!

Selected Publications
------

### RL for LLMs
- [Regularizing Hidden States Enables Learning Generalizable Reward Model for LLMs](https://arxiv.org/abs/2406.10216). Preprint, 2024.

  **Rui Yang**, Ruomeng Ding, Yong Lin, Huan Zhang, Tong Zhang.

  - <small>**TL;DR:** Enhancing the generalization ability of reward models for LLMs via text-generation regularizations.</small>

- [Rewards-in-Context: Multi-objective Alignment of Foundation Models with Dynamic Preference Adjustment](https://arxiv.org/abs/2402.10207). International Conference on Machine Learning (ICML) 2024.

  **Rui Yang** $^\*$, Xiaoman Pan $^\*$, Feng Luo $^\*$, Shuang Qiu $^\*$, Han Zhong, Dong Yu, Jianshu Chen.

   - <small>**TL;DR:** Efficient and scalable multi-objective alignment for foundation models through multi-reward conditional SFT and inference-time adaption.</small>

### Robust Offline RL

- [Towards Robust Offline Reinforcement Learning under Diverse Data Corruption](https://openreview.net/forum?id=5hAMmCU0bK). International Conference on Learning Representations (ICLR) 2024. $\\color{red}{\\text{(Spotlight)}}$
  
  **Rui Yang** $^\*$, Han Zhong $^\*$, Jiawei Xu $^\*$, Amy Zhang, Chongjie Zhang, Lei Han, Tong Zhang.

  - <small>**TL;DR:** SOTA robust offline RL against data corruption through robust value learning and moderate pessimism.</small>

- [Corruption-Robust Offline Reinforcement Learning with General Function Approximation](https://openreview.net/forum?id=K9M7XNS9BX). Neural Information Processing Systems (NeurIPS) 2023.

  Chenlu Ye $^\*$, **Rui Yang** $^\*$, Quanquan Gu, Tong Zhang.

  - <small>**TL;DR:** Provable robust offline RL method against reward and dynamics corruption in offline data through uncertainty reweighting.</small>

- [RORL: Robust Offline Reinforcement Learning via Conservative Smoothing](https://openreview.net/forum?id=_QzJJGH_KE). Neural Information Processing Systems (NeurIPS) 2022. $\color{red}{\text{(Spotlight)}}$
  
  **Rui Yang** $^\*$, Chenjia Bai $^\*$, Xiaoteng Ma, Zhaoran Wang, Chongjie Zhang, Lei Han.

  - <small>**TL;DR:** Robust offline RL method against testing-time observation perturbation through pessimism and local smoothing.</small>

  
### Goal-conditioend RL

- [What Is Essential for Unseen Goal Generalization of Offline Goal-conditioned RL?](https://openreview.net/forum?id=UrQySwOk4q). International Conference on Machine Learning (ICML) 2023. 

  **Rui Yang**, Yong Lin, Xiaoteng Ma, Hao Hu, Chongjie Zhang, Tong Zhang.

   - <small>**TL;DR:** We study the unseen goal generalization ability of offline GCRL, and propose to enhance the OOD generalization.</small>

- [Rethinking Goal-conditioned Supervised Learning and Its Connection to Offline RL](https://openreview.net/forum?id=KJztlfGPdwW). International Conference on Learning Representations (ICLR), 2022. 

  **Rui Yang**, Yiming Lu, Wenzhe Li, Hao Sun, Meng Fang, Yali Du, Xiu Li, Lei Han, Chongjie Zhang.

  - <small>**TL;DR:** An efficient supervised-based offline GCRL method with three effective weighting techniques.</small>
  
- [GOPlan: Goal-conditioned Offline Reinforcement Learning by Planning with Learned Models](https://openreview.net/forum?id=zOKAmm8R9B). Transactions on Machine Learning Research (TMLR) 2024.

  Mianchu Wang $^\*$, **Rui Yang $^\*$**, Xi Chen, Hao Sun, Meng Fang, Giovanni Montana.
  
    - <small>**TL;DR:** Pretraining prior policy via advantage-weighted CGAN and leveraging reanalysis with model-based planning for policy improvement.</small>



Experiences
------
-  Internship at Tencent AI Lab

-  Internship at Meituan Financial Service Group

Services
------
Conference Reviewer: ICML (22,24), ICLR (24, 25), NeurIPS (22,23 $\\color{red}{\\text{Top Reviewer}}$, 24), ICRA (23), AAMAS(24). 

Journal Reviewer: IEEE Robotics and Automation Letters (RA-L), IEEE Transactions on Artificial Intelligence (TAI), Machine Learning.

Teaching Assistant: COMP 4211 Machine Learning, HKUSt; COMP 1021 Introduction to Computer Science, HKUST


Others
------
In my leisure time, I enjoy sports like running, table tennis, and swimming. During my time at Tsinghua University, I was an amateur long-distance runner. In 2019, I completed a half marathon (21.0975 km) in 1 h 30 m and a full marathon (42.195 km) in 3 h 36 m.
